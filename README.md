# VisDrone MOT to YOLO Converter & Training Pipeline

## ğŸ“‹ DescriÃ§Ã£o

Este projeto Ã© um pipeline completo para conversÃ£o do dataset VisDrone MOT (Multiple Object Tracking) para o formato YOLO e treinamento de modelos de detecÃ§Ã£o de objetos. O sistema foi otimizado para execuÃ§Ã£o no Google Colab com recursos limitados, processando apenas uma amostra reduzida do dataset para evitar problemas de timeout.

## ğŸš€ CaracterÃ­sticas Principais

- **ConversÃ£o AutomÃ¡tica**: Converte anotaÃ§Ãµes VisDrone para formato YOLO
- **Pipeline de Treinamento**: Treinamento completo com YOLOv11
- **AvaliaÃ§Ã£o Integrada**: Sistema de mÃ©tricas e relatÃ³rios automÃ¡ticos
- **Otimizado para Colab**: Configurado para recursos limitados
- **VisualizaÃ§Ãµes**: GrÃ¡ficos e matrizes de confusÃ£o automÃ¡ticos
- **RelatÃ³rios HTML**: RelatÃ³rios detalhados de performance

## ğŸ“Š Dataset Suportado

O projeto trabalha com o dataset **VisDrone MOT** que contÃ©m:
- **Classes**: pedestrian, people, car, van, truck, bus, motorcycle
- **Formato Original**: AnotaÃ§Ãµes em formato VisDrone
- **Formato Destino**: YOLO (normalizado)

### Mapeamento de Classes
```
VisDrone â†’ YOLO
1 (pedestrian) â†’ 0 (person)
2 (people) â†’ 0 (person)
4 (car) â†’ 1 (car)
5 (van) â†’ 2 (van)
6 (truck) â†’ 3 (truck)
9 (bus) â†’ 4 (bus)
10 (motor) â†’ 5 (motorcycle)
```

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
```bash
# Instalar dependÃªncias principais
pip install ultralytics
pip install polars
pip install numpy
pip install pillow
pip install tqdm
pip install matplotlib
pip install seaborn
pip install pandas
pip install opencv-python
pip install scikit-learn
```

### ConfiguraÃ§Ã£o do Google Drive
1. Monte seu Google Drive no Colab:
```python
from google.colab import drive
drive.mount('/content/drive')
```

2. Organize seus dados no Drive:
```
/content/drive/MyDrive/visdrone_mot/
â”œâ”€â”€ yolov8_detection/
â”‚   â”œâ”€â”€ MOT-TRAIN/
â”‚   â”‚   â”œâ”€â”€ sequences/
â”‚   â”‚   â””â”€â”€ annotations/
â”‚   â””â”€â”€ MOT-VAL/
â”‚       â”œâ”€â”€ sequences/
â”‚       â””â”€â”€ annotations/
```

## ğŸ¯ Como Usar

### 1. ConversÃ£o VisDrone â†’ YOLO

```python
# Executar conversÃ£o
python mot4.py
```

**ConfiguraÃ§Ãµes PadrÃ£o:**
- MÃ¡ximo 60 sequÃªncias
- MÃ¡ximo 100 imagens por sequÃªncia
- Split 80% train / 20% val
- Classes mapeadas automaticamente

### 2. Treinamento do Modelo

```python
# Executar pipeline completo de treinamento
from mot4 import run_complete_training_pipeline

success = run_complete_training_pipeline()
```

**ParÃ¢metros de Treinamento:**
- Modelo: YOLOv11n (nano)
- Ã‰pocas: 50
- Batch Size: 16
- Tamanho da Imagem: 768px
- Learning Rate: 0.01

### 3. Usar Modelo Treinado

```python
from ultralytics import YOLO

# Carregar modelo treinado
model = YOLO('/content/drive/MyDrive/visdrone_weights/visdrone_best.pt')

# Fazer prediÃ§Ãµes
results = model('sua_imagem.jpg')

# Visualizar resultados
results[0].show()
```

## ğŸ“ Estrutura de Arquivos

```
MOT4/
â”œâ”€â”€ mot4.py                          # Arquivo principal
â”œâ”€â”€ README.md                        # Este arquivo
â””â”€â”€ outputs/
    â”œâ”€â”€ visdrone_yolo/               # Dataset convertido
    â”‚   â”œâ”€â”€ images/
    â”‚   â”‚   â”œâ”€â”€ train/
    â”‚   â”‚   â””â”€â”€ val/
    â”‚   â”œâ”€â”€ labels/
    â”‚   â”‚   â”œâ”€â”€ train/
    â”‚   â”‚   â””â”€â”€ val/
    â”‚   â””â”€â”€ dataset.yaml
    â”œâ”€â”€ visdrone_weights/            # Pesos treinados
    â”‚   â”œâ”€â”€ visdrone_best.pt
    â”‚   â””â”€â”€ visdrone_last.pt
    â””â”€â”€ visdrone_results/            # RelatÃ³rios e mÃ©tricas
        â”œâ”€â”€ training_evaluation_report.html
        â”œâ”€â”€ training_metrics.json
        â”œâ”€â”€ metrics_overview.png
        â””â”€â”€ confusion_matrix.png
```

## ğŸ“Š MÃ©tricas e AvaliaÃ§Ã£o

O sistema gera automaticamente:

### MÃ©tricas Principais
- **mAP@0.5**: Mean Average Precision com IoU 0.5
- **mAP@0.5:0.95**: Mean Average Precision com IoU 0.5-0.95
- **Precision**: PrecisÃ£o mÃ©dia
- **Recall**: Recall mÃ©dio
- **F1-Score**: Score F1 balanceado

### MÃ©tricas por Classe
- AP@0.5 e AP@0.5:0.95 para cada classe
- Precision e Recall individuais
- AnÃ¡lise de confusÃ£o entre classes

### MÃ©tricas de Performance
- Tempo de inferÃªncia por imagem
- FPS (Frames Per Second)
- Tempo total de treinamento

## ğŸ¨ VisualizaÃ§Ãµes Geradas

1. **VisÃ£o Geral das MÃ©tricas**: GrÃ¡fico com todas as mÃ©tricas principais
2. **Matriz de ConfusÃ£o**: AnÃ¡lise de erros de classificaÃ§Ã£o
3. **MÃ©tricas por Classe**: Performance individual de cada classe
4. **Precision vs Recall**: AnÃ¡lise de trade-off

## ğŸ“„ RelatÃ³rios

### RelatÃ³rio HTML
- Interface web completa
- MÃ©tricas organizadas em cards
- Tabelas de performance por classe
- RecomendaÃ§Ãµes baseadas nos resultados
- VisualizaÃ§Ãµes integradas

### Arquivo JSON
- Dados estruturados para anÃ¡lise posterior
- ConfiguraÃ§Ãµes de treinamento
- MÃ©tricas numÃ©ricas
- Caminhos dos arquivos gerados

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Personalizar ConversÃ£o
```python
from mot4 import Config, VisDroneConverter

# ConfiguraÃ§Ã£o personalizada
config = Config(
    max_sequences=100,           # Mais sequÃªncias
    max_images_per_sequence=200, # Mais imagens por sequÃªncia
    train_val_split=0.9          # Split diferente
)

converter = VisDroneConverter(config)
converter.run_conversion()
```

### Personalizar Treinamento
```python
from mot4 import TrainingConfig, YOLOTrainer

# ConfiguraÃ§Ã£o de treinamento personalizada
config = TrainingConfig()
config.epochs = 100              # Mais Ã©pocas
config.batch_size = 32           # Batch maior
config.img_size = 1024          # Imagens maiores
config.base_model = "yolo11s.pt" # Modelo maior

trainer = YOLOTrainer(config)
trainer.train()
```

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Problemas Comuns

1. **Erro de memÃ³ria no Colab**
   - Reduza `max_sequences` e `max_images_per_sequence`
   - Use modelo YOLOv11n (nano)

2. **Dataset nÃ£o encontrado**
   - Verifique se o Google Drive estÃ¡ montado
   - Confirme a estrutura de diretÃ³rios

3. **Timeout no treinamento**
   - Reduza o nÃºmero de Ã©pocas
   - Use batch size menor
   - Salve checkpoints com mais frequÃªncia

### Logs e Debug
O sistema gera logs detalhados com emojis para facilitar o acompanhamento:
- ğŸš€ InÃ­cio de operaÃ§Ãµes
- âœ… Sucessos
- âŒ Erros
- âš ï¸ Avisos
- ğŸ“Š EstatÃ­sticas

## ğŸ“ˆ Performance Esperada

### Com Dataset Reduzido (60 sequÃªncias)
- **Tempo de ConversÃ£o**: ~5-10 minutos
- **Tempo de Treinamento**: ~30-60 minutos
- **mAP@0.5 Esperado**: 0.3-0.6 (dependendo da qualidade dos dados)

### Com Dataset Completo
- **Tempo de ConversÃ£o**: ~2-4 horas
- **Tempo de Treinamento**: ~4-8 horas
- **mAP@0.5 Esperado**: 0.5-0.8

## ğŸ¤ ContribuiÃ§Ã£o

Para contribuir com o projeto:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido com prÃ¡ticas modernas de Python e otimizado para Google Colab.

## ğŸ”— Links Ãšteis

- [Dataset VisDrone](https://github.com/VisDrone/VisDrone-Dataset)
- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [Google Colab](https://colab.research.google.com/)

---

**Nota**: Este projeto foi otimizado para execuÃ§Ã£o no Google Colab com recursos limitados. Para uso em ambiente local com mais recursos, ajuste as configuraÃ§Ãµes conforme necessÃ¡rio.
