# -*- coding: utf-8 -*-
"""MOT4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T7uU7LYVZVC1pqLtDpDgbfldgyHeV8AT
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install ultralytics

"""
VisDrone to YOLO Format Converter - Vers√£o Compacta (60 amostras)

Este m√≥dulo converte uma pequena amostra do dataset VisDrone MOT para formato YOLO,
usando apenas 60 sequ√™ncias para evitar problemas de timeout no Google Colab.

Autor: Desenvolvido com pr√°ticas modernas de Python
Vers√£o: 2.3 - Compacta
"""

import os
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, NamedTuple
from dataclasses import dataclass
import random

import polars as pl
import numpy as np
from PIL import Image
from tqdm import tqdm


# ======================================================================================
# --- CONFIGURA√á√ïES E ESTRUTURAS DE DADOS ---
# ======================================================================================

@dataclass
class Config:
    """Configura√ß√µes do conversor VisDrone para YOLO."""

    # Caminhos base
    gdrive_visdrone_path: str = "/content/drive/MyDrive/visdrone_mot"
    gdrive_output_path: str = "/content/drive/MyDrive/visdrone_mot/visdrone_yolo"
    local_visdrone_path: str = "/content/visdrone_mot"
    local_output_path: str = "/content/visdrone_yolo"

    # Configura√ß√µes de processamento - REDUZIDAS para Colab
    max_sequences: int = 60  # Apenas 60 sequ√™ncias
    max_images_per_sequence: int = 100  # M√°ximo 100 imagens por sequ√™ncia
    train_val_split: float = 0.8  # 80% train, 20% val dos mesmos dados

    # Mapeamento de classes VisDrone -> YOLO
    class_mapping: Dict[int, int] = None

    def __post_init__(self):
        if self.class_mapping is None:
            self.class_mapping = {
                1: 0,  # pedestrian -> person
                2: 0,  # people -> person
                4: 1,  # car -> car
                5: 2,  # van -> van
                6: 3,  # truck -> truck
                9: 4,  # bus -> bus
                10: 5, # motor -> motorcycle
            }


class BoundingBox(NamedTuple):
    """Representa uma bounding box normalizada."""
    class_id: int
    x_center: float
    y_center: float
    width: float
    height: float


class ProcessingStats:
    """Estat√≠sticas de processamento para monitoramento."""

    def __init__(self):
        self.images_processed = 0
        self.annotations_processed = 0
        self.errors = 0
        self.skipped_images = 0
        self.sequences_processed = 0

    def update(self, images: int = 0, annotations: int = 0, errors: int = 0, skipped: int = 0, sequences: int = 0):
        self.images_processed += images
        self.annotations_processed += annotations
        self.errors += errors
        self.skipped_images += skipped
        self.sequences_processed += sequences

    def __str__(self):
        return (f"Processamento: {self.sequences_processed} sequ√™ncias, "
                f"{self.images_processed} imagens, "
                f"{self.annotations_processed} anota√ß√µes, "
                f"{self.errors} erros, {self.skipped_images} ignoradas")


# ======================================================================================
# --- CONFIGURA√á√ÉO DE LOGGING ---
# ======================================================================================

def setup_logging(level: int = logging.INFO) -> logging.Logger:
    """
    Configura sistema de logging com formata√ß√£o personalizada.

    Args:
        level: N√≠vel de logging (default: INFO)

    Returns:
        Logger configurado
    """
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler()]
    )
    return logging.getLogger(__name__)


# ======================================================================================
# --- UTILIT√ÅRIOS DE I/O ---
# ======================================================================================

class DataManager:
    """Gerenciador de dados com otimiza√ß√µes para datasets pequenos."""

    def __init__(self, config: Config, logger: logging.Logger):
        self.config = config
        self.logger = logger

    def setup_local_storage(self) -> bool:
        """
        Configura armazenamento local copiando apenas algumas sequ√™ncias do Google Drive.

        Returns:
            True se bem-sucedido, False caso contr√°rio
        """
        local_path = Path(self.config.local_visdrone_path)
        gdrive_path = Path(self.config.gdrive_visdrone_path)

        if not gdrive_path.exists():
            self.logger.error(f"‚ùå Caminho do Google Drive n√£o encontrado: {gdrive_path}")
            return False

        try:
            # Limpar dados locais anteriores
            if local_path.exists():
                shutil.rmtree(local_path)

            self.logger.info("üîÑ Copiando estrutura b√°sica...")

            # Criar estrutura b√°sica
            local_path.mkdir(parents=True, exist_ok=True)

            # Copiar apenas a estrutura necess√°ria
            gdrive_detection_path = gdrive_path / "yolov8_detection"
            local_detection_path = local_path / "yolov8_detection"

            if gdrive_detection_path.exists():
                self._copy_subset_data(gdrive_detection_path, local_detection_path)

            self.logger.info("‚úÖ C√≥pia de dados reduzida conclu√≠da!")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Erro na c√≥pia: {e}")
            return False

    def _copy_subset_data(self, gdrive_path: Path, local_path: Path):
        """Copia apenas um subset dos dados para economizar espa√ßo."""
        for subset in ['MOT-TRAIN', 'MOT-VAL']:
            gdrive_subset = gdrive_path / subset
            local_subset = local_path / subset

            if not gdrive_subset.exists():
                continue

            # Criar diret√≥rios
            (local_subset / 'sequences').mkdir(parents=True, exist_ok=True)
            (local_subset / 'annotations').mkdir(parents=True, exist_ok=True)

            # Copiar apenas algumas sequ√™ncias
            seq_source = gdrive_subset / 'sequences'
            ann_source = gdrive_subset / 'annotations'

            if seq_source.exists():
                sequences = list(seq_source.iterdir())[:self.config.max_sequences]

                for seq in sequences:
                    if seq.is_dir():
                        # Copiar sequ√™ncia completa
                        dest_seq = local_subset / 'sequences' / seq.name
                        shutil.copytree(seq, dest_seq)

                        # Copiar anota√ß√£o correspondente
                        ann_file = ann_source / f"{seq.name}.txt"
                        if ann_file.exists():
                            dest_ann = local_subset / 'annotations' / f"{seq.name}.txt"
                            shutil.copy2(ann_file, dest_ann)

    def create_output_structure(self) -> bool:
        """
        Cria estrutura de diret√≥rios de sa√≠da.

        Returns:
            True se bem-sucedido, False caso contr√°rio
        """
        try:
            output_path = Path(self.config.local_output_path)

            for subset in ['train', 'val']:
                (output_path / 'images' / subset).mkdir(parents=True, exist_ok=True)
                (output_path / 'labels' / subset).mkdir(parents=True, exist_ok=True)

            self.logger.info("üìÅ Estrutura de diret√≥rios criada")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao criar estrutura: {e}")
            return False

    def backup_to_drive(self) -> bool:
        """
        Faz backup dos resultados para o Google Drive.

        Returns:
            True se bem-sucedido, False caso contr√°rio
        """
        try:
            local_path = Path(self.config.local_output_path)
            gdrive_path = Path(self.config.gdrive_output_path)

            if gdrive_path.exists():
                shutil.rmtree(gdrive_path)

            self.logger.info("üì§ Copiando resultados para Google Drive...")
            shutil.copytree(local_path, gdrive_path)

            # Criar arquivo dataset.yaml
            self._create_dataset_yaml(gdrive_path)

            self.logger.info(f"‚úÖ Backup conclu√≠do em: {gdrive_path}")
            return True
        except Exception as e:
            self.logger.error(f"‚ùå Erro no backup: {e}")
            return False

    def _create_dataset_yaml(self, output_path: Path):
        """Cria arquivo de configura√ß√£o do dataset YOLO."""
        yaml_content = f"""# Dataset YOLO gerado a partir do VisDrone
path: {output_path}
train: images/train
val: images/val

# N√∫mero de classes
nc: 6

# Nomes das classes
names:
  0: person
  1: car
  2: van
  3: truck
  4: bus
  5: motorcycle
"""
        yaml_file = output_path / "dataset.yaml"
        with open(yaml_file, 'w', encoding='utf-8') as f:
            f.write(yaml_content)


# ======================================================================================
# --- PROCESSAMENTO DE ANOTA√á√ïES ---
# ======================================================================================

class AnnotationProcessor:
    """Processador de anota√ß√µes usando Polars para alta performance."""

    def __init__(self, config: Config, logger: logging.Logger):
        self.config = config
        self.logger = logger

    def load_annotations_fast(self, annotation_file: Path) -> Optional[pl.DataFrame]:
        """
        Carrega anota√ß√µes usando Polars para processamento r√°pido.

        Args:
            annotation_file: Caminho para arquivo de anota√ß√µes

        Returns:
            DataFrame com anota√ß√µes ou None se erro
        """
        try:
            if not annotation_file.exists():
                return pl.DataFrame()

            # Schema para anota√ß√µes VisDrone
            schema = {
                'frame_id': pl.Int32,
                'target_id': pl.Int32,
                'bbox_left': pl.Int32,
                'bbox_top': pl.Int32,
                'bbox_width': pl.Int32,
                'bbox_height': pl.Int32,
                'score': pl.Int32,
                'object_category': pl.Int32,
                'truncation': pl.Float32,
                'occlusion': pl.Int32
            }

            df = pl.read_csv(
                annotation_file,
                has_header=False,
                schema=schema,
                separator=',',
                truncate_ragged_lines=True
            )

            # Filtrar apenas objetos v√°lidos
            df = df.filter(
                (pl.col('score') > 0) &
                (pl.col('object_category').is_in(list(self.config.class_mapping.keys())))
            )

            return df

        except Exception as e:
            self.logger.error(f"‚ùå Erro ao carregar anota√ß√µes {annotation_file}: {e}")
            return None

    def get_frame_annotations(self, df: pl.DataFrame, frame_id: int) -> List[dict]:
        """
        Extrai anota√ß√µes para um frame espec√≠fico.

        Args:
            df: DataFrame com anota√ß√µes
            frame_id: ID do frame

        Returns:
            Lista de dicion√°rios com dados das bounding boxes
        """
        if df.is_empty():
            return []

        frame_data = df.filter(pl.col('frame_id') == frame_id)
        return frame_data.to_dicts()


# ======================================================================================
# --- PROCESSAMENTO DE IMAGENS ---
# ======================================================================================

class ImageProcessor:
    """Processador de imagens com otimiza√ß√µes de mem√≥ria."""

    def __init__(self, config: Config, logger: logging.Logger):
        self.config = config
        self.logger = logger

    @staticmethod
    def get_image_dimensions_fast(image_path: Path) -> Tuple[Optional[int], Optional[int]]:
        """
        Obt√©m dimens√µes da imagem de forma eficiente.

        Args:
            image_path: Caminho da imagem

        Returns:
            Tupla (largura, altura) ou (None, None) se erro
        """
        try:
            with Image.open(image_path) as img:
                return img.size
        except Exception:
            return None, None

    def convert_bbox_to_yolo(self, bbox_data: dict, img_width: int, img_height: int) -> BoundingBox:
        """
        Converte bounding box VisDrone para formato YOLO.

        Args:
            bbox_data: Dados da bounding box
            img_width: Largura da imagem
            img_height: Altura da imagem

        Returns:
            BoundingBox normalizada no formato YOLO
        """
        bbox_left = bbox_data['bbox_left']
        bbox_top = bbox_data['bbox_top']
        bbox_width = bbox_data['bbox_width']
        bbox_height = bbox_data['bbox_height']

        # Converter para coordenadas centrais normalizadas
        x_center = (bbox_left + bbox_width / 2) / img_width
        y_center = (bbox_top + bbox_height / 2) / img_height
        width = bbox_width / img_width
        height = bbox_height / img_height

        # Mapear classe
        yolo_class_id = self.config.class_mapping[bbox_data['object_category']]

        return BoundingBox(yolo_class_id, x_center, y_center, width, height)


# ======================================================================================
# --- PROCESSADOR PRINCIPAL ---
# ======================================================================================

class VisDroneConverter:
    """Conversor principal VisDrone para YOLO - Vers√£o compacta."""

    def __init__(self, config: Config):
        self.config = config
        self.logger = setup_logging()
        self.data_manager = DataManager(config, self.logger)
        self.annotation_processor = AnnotationProcessor(config, self.logger)
        self.image_processor = ImageProcessor(config, self.logger)
        self.stats = ProcessingStats()
        self.processed_data = []  # Armazenar dados processados para reutilizar

    def setup(self) -> bool:
        """
        Configura ambiente para convers√£o.

        Returns:
            True se configura√ß√£o bem-sucedida
        """
        self.logger.info("üöÄ Iniciando setup do VisDrone Converter (vers√£o compacta)...")

        if not self.data_manager.setup_local_storage():
            return False

        if not self.data_manager.create_output_structure():
            return False

        self.logger.info("‚úÖ Setup conclu√≠do!")
        return True

    def collect_all_data(self) -> List[Tuple[str, str, List[dict]]]:
        """
        Coleta todos os dados dispon√≠veis primeiro.

        Returns:
            Lista com tuplas (sequencia, imagem, anotacoes)
        """
        self.logger.info("üìä Coletando dados dispon√≠veis...")
        all_data = []

        # Verificar dados de treino primeiro
        base_path = Path(self.config.local_visdrone_path) / "yolov8_detection" / "MOT-TRAIN"
        seq_path = base_path / "sequences"
        ann_path = base_path / "annotations"

        if not seq_path.exists():
            self.logger.warning("‚ö†Ô∏è  Pasta MOT-TRAIN n√£o encontrada, tentando MOT-VAL...")
            base_path = Path(self.config.local_visdrone_path) / "yolov8_detection" / "MOT-VAL"
            seq_path = base_path / "sequences"
            ann_path = base_path / "annotations"

        if not seq_path.exists():
            self.logger.error("‚ùå Nenhuma pasta de sequ√™ncias encontrada!")
            return []

        sequences = [s for s in seq_path.iterdir() if s.is_dir()]
        sequences = sequences[:self.config.max_sequences]

        for seq_dir in sequences:
            seq_name = seq_dir.name
            self.logger.info(f"üìÇ Processando sequ√™ncia: {seq_name}")

            # Carregar anota√ß√µes
            annotation_file = ann_path / f"{seq_name}.txt"
            df_annotations = self.annotation_processor.load_annotations_fast(annotation_file)

            if df_annotations is None or df_annotations.is_empty():
                self.logger.warning(f"‚ö†Ô∏è  Sem anota√ß√µes para {seq_name}")
                continue

            # Processar imagens da sequ√™ncia
            image_files = sorted([f for f in seq_dir.iterdir()
                                if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])

            # Limitar n√∫mero de imagens por sequ√™ncia
            image_files = image_files[:self.config.max_images_per_sequence]

            for img_file in image_files:
                frame_id = int(img_file.stem)
                frame_annotations = self.annotation_processor.get_frame_annotations(
                    df_annotations, frame_id
                )

                if frame_annotations:  # S√≥ adicionar se tiver anota√ß√µes
                    all_data.append((seq_name, img_file.name, frame_annotations))

            self.stats.update(sequences=1)

        self.logger.info(f"üìä Coletados {len(all_data)} exemplos de {len(sequences)} sequ√™ncias")
        return all_data

    def process_single_image(self, seq_name: str, img_name: str, frame_annotations: List[dict],
                           subset: str) -> Tuple[bool, int]:
        """
        Processa uma √∫nica imagem.

        Args:
            seq_name: Nome da sequ√™ncia
            img_name: Nome da imagem
            frame_annotations: Anota√ß√µes do frame
            subset: 'train' ou 'val'

        Returns:
            Tupla (sucesso, num_anota√ß√µes)
        """
        try:
            # Encontrar arquivo de imagem original
            source_paths = [
                Path(self.config.local_visdrone_path) / "yolov8_detection" / "MOT-TRAIN" / "sequences" / seq_name / img_name,
                Path(self.config.local_visdrone_path) / "yolov8_detection" / "MOT-VAL" / "sequences" / seq_name / img_name
            ]

            source_img_path = None
            for path in source_paths:
                if path.exists():
                    source_img_path = path
                    break

            if not source_img_path:
                return False, 0

            # Verificar dimens√µes da imagem
            img_width, img_height = self.image_processor.get_image_dimensions_fast(source_img_path)
            if not img_width or not img_height:
                return False, 0

            # Copiar imagem
            new_img_name = f"{seq_name}_{img_name}"
            output_img_path = Path(self.config.local_output_path) / "images" / subset
            dest_img_path = output_img_path / new_img_name
            shutil.copy2(source_img_path, dest_img_path)

            # Processar anota√ß√µes
            yolo_annotations = []
            for bbox_data in frame_annotations:
                bbox = self.image_processor.convert_bbox_to_yolo(bbox_data, img_width, img_height)
                yolo_annotations.append(
                    f"{bbox.class_id} {bbox.x_center:.6f} {bbox.y_center:.6f} "
                    f"{bbox.width:.6f} {bbox.height:.6f}"
                )

            # Salvar arquivo de label
            label_filename = Path(new_img_name).stem + ".txt"
            output_lbl_path = Path(self.config.local_output_path) / "labels" / subset
            label_path = output_lbl_path / label_filename

            with open(label_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(yolo_annotations))

            return True, len(yolo_annotations)

        except Exception as e:
            self.logger.error(f"‚ùå Erro processando {seq_name}/{img_name}: {e}")
            return False, 0

    def run_conversion(self) -> bool:
        """
        Executa convers√£o completa usando os mesmos dados para train e val.

        Returns:
            True se convers√£o bem-sucedida
        """
        self.logger.info("üöÄ Iniciando convers√£o VisDrone -> YOLO (vers√£o compacta)")

        if not self.setup():
            return False

        # Coletar todos os dados dispon√≠veis
        all_data = self.collect_all_data()
        if not all_data:
            self.logger.error("‚ùå Nenhum dado encontrado!")
            return False

        # Embaralhar dados para melhor distribui√ß√£o
        random.shuffle(all_data)

        # Dividir entre train e val
        split_point = int(len(all_data) * self.config.train_val_split)
        train_data = all_data[:split_point]
        val_data = all_data[split_point:]

        # Se val_data estiver vazio, usar alguns dados de train
        if not val_data:
            val_data = train_data[:min(2, len(train_data))]

        self.logger.info(f"üìä Divis√£o: {len(train_data)} train, {len(val_data)} val")

        # Processar train
        self.logger.info("üîÑ Processando dados de treino...")
        for seq_name, img_name, frame_annotations in tqdm(train_data, desc="Train"):
            success, annotations = self.process_single_image(
                seq_name, img_name, frame_annotations, 'train'
            )
            self.stats.update(
                images=1 if success else 0,
                annotations=annotations,
                errors=0 if success else 1
            )

        # Processar val
        self.logger.info("üîÑ Processando dados de valida√ß√£o...")
        for seq_name, img_name, frame_annotations in tqdm(val_data, desc="Val"):
            success, annotations = self.process_single_image(
                seq_name, img_name, frame_annotations, 'val'
            )
            self.stats.update(
                images=1 if success else 0,
                annotations=annotations,
                errors=0 if success else 1
            )

        # Estat√≠sticas finais
        self.logger.info("üìä Estat√≠sticas finais:")
        self.logger.info(str(self.stats))

        # Backup para Google Drive
        self.data_manager.backup_to_drive()

        self.logger.info("üéâ Convers√£o conclu√≠da com sucesso!")
        self.logger.info(f"üìÅ Dados YOLO dispon√≠veis em: {self.config.gdrive_output_path}")

        return True


# ======================================================================================
# --- EXECU√á√ÉO PRINCIPAL ---
# ======================================================================================

def main():
    """Fun√ß√£o principal de execu√ß√£o."""
    # Configura√ß√£o para processamento pequeno
    config = Config(
        max_sequences=20,
        max_images_per_sequence=100,
        train_val_split=0.8
    )

    # Executar convers√£o
    converter = VisDroneConverter(config)
    success = converter.run_conversion()

    if success:
        print("üéâ Convers√£o finalizada com sucesso!")
        print(f"üìÅ Confira os resultados em: {config.gdrive_output_path}")
        print("üìÑ Arquivo dataset.yaml criado para uso com YOLO!")
    else:
        print("‚ùå Convers√£o falhou. Verifique os logs.")


if __name__ == '__main__':
    main()

"""
Pipeline Completo YOLO para Dataset VisDrone
Treinamento + Sistema de Avalia√ß√£o e Relat√≥rios Integrado

Autor: Pipeline de ML moderno
Vers√£o: 3.0 - Integrado
"""

import os
import shutil
import yaml
import json
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Optional, NamedTuple
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

try:
    from ultralytics import YOLO
    from ultralytics.utils.metrics import ConfusionMatrix
    print("‚úÖ Ultralytics j√° instalado!")
except ImportError:
    print("üîÑ Instalando ultralytics...")
    !pip install ultralytics -q
    from ultralytics import YOLO
    from ultralytics.utils.metrics import ConfusionMatrix

import torch
import numpy as np
from sklearn.metrics import precision_recall_curve, average_precision_score
import cv2
from PIL import Image, ImageDraw, ImageFont
from collections import defaultdict
import time


# ======================================================================================
# --- CONFIGURA√á√ïES DE TREINAMENTO ---
# ======================================================================================

class TrainingConfig:
    """Configura√ß√µes de treinamento otimizadas para Colab."""

    def __init__(self):
        # Caminhos
        self.dataset_path = "/content/drive/MyDrive/visdrone_mot/visdrone_yolo"
        self.weights_path = "/content/drive/MyDrive/visdrone_weights"
        self.results_path = "/content/drive/MyDrive/visdrone_results"

        # Par√¢metros de treinamento (otimizados para Colab)
        self.epochs = 50  # Reduzido para evitar timeout
        self.batch_size = 16  # Ajustado para GPU do Colab
        self.img_size = 768
        self.patience = 10  # Early stopping

        # Modelo base
        self.base_model = "yolo11n.pt"  # Nano para ser mais r√°pido

        # Hiperpar√¢metros
        self.lr0 = 0.01  # Learning rate inicial
        self.momentum = 0.937
        self.weight_decay = 0.0005
        self.warmup_epochs = 3

        # GPU/Device
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

    def create_directories(self):
        """Cria diret√≥rios necess√°rios."""
        for path in [self.weights_path, self.results_path]:
            Path(path).mkdir(parents=True, exist_ok=True)


# ======================================================================================
# --- VERIFICA√á√ÉO E PREPARA√á√ÉO DO DATASET ---
# ======================================================================================

class DatasetValidator:
    """Validador e preparador do dataset."""

    def __init__(self, config: TrainingConfig):
        self.config = config

    def validate_dataset(self) -> bool:
        """
        Valida se o dataset est√° corretamente estruturado.

        Returns:
            True se v√°lido, False caso contr√°rio
        """
        print("üîç Validando estrutura do dataset...")

        dataset_path = Path(self.config.dataset_path)
        yaml_file = dataset_path / "dataset.yaml"

        # Verificar se existe o arquivo YAML
        if not yaml_file.exists():
            print("‚ùå Arquivo dataset.yaml n√£o encontrado!")
            return False

        # Verificar estrutura de diret√≥rios
        required_dirs = [
            "images/train", "images/val",
            "labels/train", "labels/val"
        ]

        for dir_path in required_dirs:
            full_path = dataset_path / dir_path
            if not full_path.exists():
                print(f"‚ùå Diret√≥rio obrigat√≥rio n√£o encontrado: {dir_path}")
                return False

        print("‚úÖ Estrutura do dataset v√°lida!")
        return True

    def analyze_dataset(self):
        """Analisa e exibe estat√≠sticas do dataset."""
        print("üìä Analisando dataset...")

        dataset_path = Path(self.config.dataset_path)

        # Contar imagens e labels
        stats = {}
        for subset in ['train', 'val']:
            img_dir = dataset_path / 'images' / subset
            lbl_dir = dataset_path / 'labels' / subset

            img_count = len(list(img_dir.glob('*.jpg'))) + len(list(img_dir.glob('*.png')))
            lbl_count = len(list(lbl_dir.glob('*.txt')))

            stats[subset] = {
                'images': img_count,
                'labels': lbl_count
            }

        print(f"üìà Estat√≠sticas do dataset:")
        print(f"   Train: {stats['train']['images']} imagens, {stats['train']['labels']} labels")
        print(f"   Val: {stats['val']['images']} imagens, {stats['val']['labels']} labels")

        return stats

    def fix_yaml_paths(self):
        """Corrige caminhos no arquivo dataset.yaml."""
        yaml_file = Path(self.config.dataset_path) / "dataset.yaml"

        if not yaml_file.exists():
            print("‚ùå dataset.yaml n√£o encontrado!")
            return False

        # Ler arquivo YAML atual
        with open(yaml_file, 'r') as f:
            data = yaml.safe_load(f)

        # Atualizar caminhos
        data['path'] = str(self.config.dataset_path)
        data['train'] = 'images/train'
        data['val'] = 'images/val'

        # Salvar arquivo corrigido
        with open(yaml_file, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False)

        print("‚úÖ Arquivo dataset.yaml atualizado!")
        return True


# ======================================================================================
# --- ESTRUTURAS DE DADOS PARA AVALIA√á√ÉO ---
# ======================================================================================

@dataclass
class MetricsConfig:
    """Configura√ß√µes para avalia√ß√£o de m√©tricas."""

    # Par√¢metros de avalia√ß√£o
    conf_threshold: float = 0.25
    iou_threshold: float = 0.5
    max_det: int = 1000

    # Par√¢metros de visualiza√ß√£o
    save_plots: bool = True
    show_plots: bool = True
    plot_width: int = 12
    plot_height: int = 8


class DetectionResult(NamedTuple):
    """Resultado de uma detec√ß√£o."""
    bbox: Tuple[float, float, float, float]  # x1, y1, x2, y2
    confidence: float
    class_id: int
    class_name: str


class EvaluationMetrics:
    """Container para m√©tricas de avalia√ß√£o."""

    def __init__(self):
        # M√©tricas principais
        self.map50: float = 0.0
        self.map50_95: float = 0.0
        self.precision: float = 0.0
        self.recall: float = 0.0
        self.f1_score: float = 0.0

        # M√©tricas por classe
        self.class_metrics: Dict[str, Dict[str, float]] = {}

        # M√©tricas de infer√™ncia
        self.inference_time: float = 0.0
        self.fps: float = 0.0

        # Dados para an√°lise
        self.confusion_matrix: Optional[np.ndarray] = None
        self.pr_curves: Dict[str, Dict[str, np.ndarray]] = {}

        # Estat√≠sticas gerais
        self.total_predictions: int = 0
        self.total_ground_truths: int = 0
        self.correct_predictions: int = 0


# ======================================================================================
# --- CALCULADOR DE M√âTRICAS INTEGRADO ---
# ======================================================================================

class IntegratedMetricsCalculator:
    """Calculador de m√©tricas integrado com o pipeline de treinamento."""

    def __init__(self, trainer: 'YOLOTrainer', config: TrainingConfig):
        self.trainer = trainer
        self.training_config = config
        self.metrics_config = MetricsConfig()
        self.class_names = []

    def calculate_metrics(self) -> EvaluationMetrics:
        """Calcula m√©tricas usando o modelo treinado."""
        if not self.trainer.model:
            raise ValueError("Modelo n√£o treinado!")

        print("üìä Calculando m√©tricas do modelo treinado...")
        metrics = EvaluationMetrics()

        try:
            # Executar valida√ß√£o oficial do YOLO
            val_results = self.trainer.model.val(
                data=str(Path(self.training_config.dataset_path) / 'dataset.yaml'),
                conf=self.metrics_config.conf_threshold,
                iou=self.metrics_config.iou_threshold,
                max_det=self.metrics_config.max_det,
                plots=True,
                save_json=True,
                verbose=True
            )

            # Extrair m√©tricas principais
            box_metrics = val_results.box
            metrics.map50 = float(box_metrics.map50)
            metrics.map50_95 = float(box_metrics.map)
            metrics.precision = float(box_metrics.mp)
            metrics.recall = float(box_metrics.mr)

            # Calcular F1 Score
            if metrics.precision > 0 and metrics.recall > 0:
                metrics.f1_score = 2 * (metrics.precision * metrics.recall) / (metrics.precision + metrics.recall)

            # Extrair nomes das classes
            if hasattr(self.trainer.model.model, 'names'):
                self.class_names = list(self.trainer.model.model.names.values())
            else:
                # Fallback to default names
                self.class_names = ['person', 'car', 'van', 'truck', 'bus', 'motorcycle']


            # M√©tricas por classe
            if hasattr(box_metrics, 'ap_class_index') and hasattr(box_metrics, 'ap'):
                for i, class_idx in enumerate(box_metrics.ap_class_index):
                    if int(class_idx) < len(self.class_names):
                        class_name = self.class_names[int(class_idx)]
                        metrics.class_metrics[class_name] = {
                            'ap50': float(box_metrics.ap50[i]) if i < len(box_metrics.ap50) else 0.0,
                            'ap50_95': float(box_metrics.ap[i]) if i < len(box_metrics.ap) else 0.0,
                            'precision': float(box_metrics.p[i]) if i < len(box_metrics.p) else 0.0,
                            'recall': float(box_metrics.r[i]) if i < len(box_metrics.r) else 0.0
                        }

            # Matriz de confus√£o
            if hasattr(val_results, 'confusion_matrix') and val_results.confusion_matrix is not None:
                metrics.confusion_matrix = val_results.confusion_matrix.matrix

            print("‚úÖ M√©tricas calculadas com sucesso!")
            return metrics

        except Exception as e:
            print(f"‚ùå Erro no c√°lculo de m√©tricas: {e}")
            return metrics


    def measure_inference_speed(self, num_images: int = 20) -> Tuple[float, float]:
        """Mede velocidade de infer√™ncia usando o dataset de valida√ß√£o."""
        if not self.trainer.model:
            raise ValueError("Modelo n√£o treinado!")

        # Usar imagens de valida√ß√£o
        val_images_path = Path(self.training_config.dataset_path) / "images" / "val"
        image_files = list(val_images_path.glob("*.jpg"))[:num_images]

        if not image_files:
            print("‚ö†Ô∏è Nenhuma imagem encontrada para teste de velocidade!")
            return 0.0, 0.0

        print(f"‚è±Ô∏è Medindo velocidade de infer√™ncia com {len(image_files)} imagens...")

        # Aquecimento da GPU
        for _ in range(5):
            if image_files:
                self.trainer.model(str(image_files[0]), verbose=False)

        # Medi√ß√£o real
        start_time = time.time()

        for img_path in image_files:
            self.trainer.model(str(img_path), verbose=False)

        total_time = time.time() - start_time
        avg_time = total_time / len(image_files)
        fps = 1.0 / avg_time if avg_time > 0 else 0.0

        print(f"Tempo m√©dio por imagem: {avg_time:.4f}s")
        print(f"FPS: {fps:.2f}")

        return avg_time, fps


# ======================================================================================
# --- VISUALIZADOR DE M√âTRICAS INTEGRADO ---
# ======================================================================================

class IntegratedMetricsVisualizer:
    """Visualizador integrado de m√©tricas."""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.results_dir = Path(config.results_path)

        # Configurar estilo dos plots
        try:
            plt.style.use('seaborn-v0_8')
        except:
            plt.style.use('default')

        try:
            sns.set_palette("husl")
        except:
            pass

    def plot_metrics_overview(self, metrics: EvaluationMetrics) -> None:
        """Cria visualiza√ß√£o geral das m√©tricas principais."""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Vis√£o Geral das M√©tricas do Modelo YOLO', fontsize=16, fontweight='bold')

        # 1. M√©tricas principais (barras)
        main_metrics = {
            'mAP@0.5': metrics.map50,
            'mAP@0.5:0.95': metrics.map50_95,
            'Precision': metrics.precision,
            'Recall': metrics.recall,
            'F1-Score': metrics.f1_score
        }

        ax1 = axes[0, 0]
        bars = ax1.bar(main_metrics.keys(), main_metrics.values(),
                       color=['#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'])
        ax1.set_title('M√©tricas Principais', fontweight='bold')
        ax1.set_ylim(0, 1)
        ax1.set_ylabel('Score')
        plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')

        # Adicionar valores nas barras
        for bar, value in zip(bars, main_metrics.values()):
            height = bar.get_height()
            ax1.annotate(f'{value:.3f}',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3), textcoords="offset points",
                        ha='center', va='bottom', fontweight='bold')

        # 2. M√©tricas por classe (mAP@0.5)
        if metrics.class_metrics:
            ax2 = axes[0, 1]
            classes = list(metrics.class_metrics.keys())
            ap_values = [metrics.class_metrics[c]['ap50'] for c in classes]

            colors = plt.cm.Set3(np.linspace(0, 1, len(classes))) if len(classes) > 0 else ['blue']
            bars = ax2.barh(classes, ap_values, color=colors)
            ax2.set_title('mAP@0.5 por Classe', fontweight='bold')
            ax2.set_xlabel('mAP@0.5')
            ax2.set_xlim(0, 1)

            # Adicionar valores
            for i, (bar, value) in enumerate(zip(bars, ap_values)):
                width = bar.get_width()
                ax2.annotate(f'{value:.3f}',
                            xy=(width, bar.get_y() + bar.get_height() / 2),
                            xytext=(3, 0), textcoords="offset points",
                            ha='left', va='center', fontsize=9)

        # 3. Compara√ß√£o Precision vs Recall
        ax3 = axes[1, 0]
        if metrics.class_metrics:
            classes = list(metrics.class_metrics.keys())
            precisions = [metrics.class_metrics[c]['precision'] for c in classes]
            recalls = [metrics.class_metrics[c]['recall'] for c in classes]

            scatter = ax3.scatter(recalls, precisions,
                                c=range(len(classes)), cmap='tab10', s=100, alpha=0.7)

            for i, class_name in enumerate(classes):
                ax3.annotate(class_name, (recalls[i], precisions[i]),
                           xytext=(5, 5), textcoords='offset points', fontsize=9)

        ax3.set_xlabel('Recall')
        ax3.set_ylabel('Precision')
        ax3.set_title('Precision vs Recall por Classe', fontweight='bold')
        ax3.set_xlim(0, 1)
        ax3.set_ylim(0, 1)
        ax3.grid(True, alpha=0.3)

        # 4. Resumo textual
        ax4 = axes[1, 1]
        ax4.axis('off')

        summary_text = f"""
RESUMO DO MODELO

Desempenho Geral:
‚Ä¢ mAP@0.5: {metrics.map50:.3f}
‚Ä¢ mAP@0.5:0.95: {metrics.map50_95:.3f}
‚Ä¢ F1-Score: {metrics.f1_score:.3f}

Velocidade:
‚Ä¢ Tempo por imagem: {metrics.inference_time:.4f}s
‚Ä¢ FPS: {metrics.fps:.1f}

Classes Detectadas: {len(metrics.class_metrics)}
        """

        ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes,
                fontsize=11, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))

        plt.tight_layout()
        plt.savefig(self.results_dir / 'metrics_overview.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_confusion_matrix(self, confusion_matrix: np.ndarray, class_names: List[str]) -> None:
        """Plota matriz de confus√£o normalizada."""
        if confusion_matrix is None or confusion_matrix.size == 0:
            print("‚ö†Ô∏è Matriz de confus√£o n√£o dispon√≠vel")
            return

        # Normalizar matriz
        with np.errstate(divide='ignore', invalid='ignore'):
            cm_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]
            cm_normalized = np.nan_to_num(cm_normalized)

        plt.figure(figsize=(10, 8))

        # Garantir que temos labels suficientes
        labels = class_names + ['Background']
        if len(labels) != cm_normalized.shape[0]:
            labels = [f'Class_{i}' for i in range(cm_normalized.shape[0])]

        sns.heatmap(cm_normalized,
                   annot=True,
                   fmt='.2f',
                   cmap='Blues',
                   xticklabels=labels,
                   yticklabels=labels,
                   cbar_kws={'label': 'Taxa de Predi√ß√£o Normalizada'})

        plt.title('Matriz de Confus√£o Normalizada', fontsize=14, fontweight='bold')
        plt.xlabel('Predi√ß√£o', fontweight='bold')
        plt.ylabel('Ground Truth', fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.results_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()


# ======================================================================================
# --- GERADOR DE RELAT√ìRIO INTEGRADO ---
# ======================================================================================

class IntegratedReportGenerator:
    """Gerador de relat√≥rio integrado."""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.results_dir = Path(config.results_path)

    def generate_html_report(self, metrics: EvaluationMetrics, training_time: float = 0) -> str:
        """Gera relat√≥rio HTML detalhado."""

        timestamp = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')

        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Relat√≥rio de Treinamento e Avalia√ß√£o - YOLO</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
        .container {{ background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; color: #333; margin-bottom: 30px; }}
        .metric-card {{ background-color: #f8f9fa; padding: 20px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #007bff; }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #007bff; }}
        .metric-label {{ font-size: 14px; color: #666; }}
        .section {{ margin: 30px 0; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background-color: #f2f2f2; font-weight: bold; }}
        .good {{ color: #28a745; }}
        .warning {{ color: #ffc107; }}
        .poor {{ color: #dc3545; }}
        .config-section {{ background-color: #e9ecef; padding: 15px; border-radius: 5px; margin: 10px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Relat√≥rio de Treinamento e Avalia√ß√£o - YOLO</h1>
            <p>Dataset: VisDrone | Data: {timestamp}</p>
        </div>

        <div class="section">
            <h2>Configura√ß√£o do Treinamento</h2>
            <div class="config-section">
                <p><strong>Modelo Base:</strong> {self.config.base_model}</p>
                <p><strong>√âpocas:</strong> {self.config.epochs}</p>
                <p><strong>Batch Size:</strong> {self.config.batch_size}</p>
                <p><strong>Tamanho da Imagem:</strong> {self.config.img_size}</p>
                <p><strong>Learning Rate:</strong> {self.config.lr0}</p>
                <p><strong>Device:</strong> {self.config.device}</p>
            </div>
        </div>

        <div class="section">
            <h2>M√©tricas de Avalia√ß√£o</h2>
            <div style="display: flex; flex-wrap: wrap; gap: 20px;">
                <div class="metric-card">
                    <div class="metric-value {'good' if metrics.map50 > 0.5 else 'warning' if metrics.map50 > 0.3 else 'poor'}">{metrics.map50:.3f}</div>
                    <div class="metric-label">mAP@0.5</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value {'good' if metrics.map50_95 > 0.3 else 'warning' if metrics.map50_95 > 0.2 else 'poor'}">{metrics.map50_95:.3f}</div>
                    <div class="metric-label">mAP@0.5:0.95</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value {'good' if metrics.precision > 0.7 else 'warning' if metrics.precision > 0.5 else 'poor'}">{metrics.precision:.3f}</div>
                    <div class="metric-label">Precision</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value {'good' if metrics.recall > 0.7 else 'warning' if metrics.recall > 0.5 else 'poor'}">{metrics.recall:.3f}</div>
                    <div class="metric-label">Recall</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value {'good' if metrics.f1_score > 0.7 else 'warning' if metrics.f1_score > 0.5 else 'poor'}">{metrics.f1_score:.3f}</div>
                    <div class="metric-label">F1-Score</div>
                </div>
            </div>
        </div>
"""

        # Adicionar tabela de m√©tricas por classe se dispon√≠vel
        if metrics.class_metrics:
            html_content += """
        <div class="section">
            <h2>Performance por Classe</h2>
            <table>
                <tr>
                    <th>Classe</th>
                    <th>AP@0.5</th>
                    <th>AP@0.5:0.95</th>
                    <th>Precision</th>
                    <th>Recall</th>
                </tr>
"""
            for class_name, class_metrics in metrics.class_metrics.items():
                html_content += f"""
                <tr>
                    <td>{class_name}</td>
                    <td>{class_metrics['ap50']:.3f}</td>
                    <td>{class_metrics['ap50_95']:.3f}</td>
                    <td>{class_metrics['precision']:.3f}</td>
                    <td>{class_metrics['recall']:.3f}</td>
                </tr>
"""
            html_content += "</table></div>"

        # Adicionar an√°lise de performance
        html_content += f"""
        <div class="section">
            <h2>An√°lise de Performance</h2>
            <table>
                <tr>
                    <th>M√©trica</th>
                    <th>Valor</th>
                    <th>Status</th>
                </tr>
                <tr>
                    <td>Tempo de Infer√™ncia</td>
                    <td>{metrics.inference_time:.4f}s</td>
                    <td class="{'good' if metrics.inference_time < 0.05 else 'warning' if metrics.inference_time < 0.1 else 'poor'}">
                        {'Excelente' if metrics.inference_time < 0.05 else 'Bom' if metrics.inference_time < 0.1 else 'Lento'}
                    </td>
                </tr>
                <tr>
                    <td>FPS</td>
                    <td>{metrics.fps:.1f}</td>
                    <td class="{'good' if metrics.fps > 20 else 'warning' if metrics.fps > 10 else 'poor'}">
                        {'Tempo Real' if metrics.fps > 20 else 'Aceit√°vel' if metrics.fps > 10 else 'Lento'}
                    </td>
                </tr>
"""

        if training_time > 0:
            hours = int(training_time // 3600)
            minutes = int((training_time % 3600) // 60)
            html_content += f"""
                <tr>
                    <td>Tempo de Treinamento</td>
                    <td>{hours}h {minutes}m</td>
                    <td>-</td>
                </tr>
"""

        html_content += """
            </table>
        </div>

        <div class="section">
            <h2>Recomenda√ß√µes</h2>
            <ul>
"""

        # Adicionar recomenda√ß√µes baseadas nas m√©tricas
        if metrics.map50 < 0.5:
            html_content += "<li><strong>mAP baixo:</strong> Considere mais √©pocas de treinamento, data augmentation ou ajuste de hiperpar√¢metros.</li>"

        if metrics.precision < 0.6:
            html_content += "<li><strong>Precis√£o baixa:</strong> Modelo tem muitos falsos positivos. Ajuste o threshold de confian√ßa.</li>"

        if metrics.recall < 0.6:
            html_content += "<li><strong>Recall baixo:</strong> Modelo est√° perdendo objetos. Considere mais dados de treinamento ou diminuir threshold.</li>"

        if metrics.fps < 10:
            html_content += "<li><strong>FPS baixo:</strong> Considere usar modelo menor (YOLOv11n) para aplica√ß√µes em tempo real.</li>"

        if not html_content.endswith("<ul>"):
            html_content += "<li><strong>Modelo bem treinado!</strong> M√©tricas est√£o dentro dos valores esperados.</li>"


        html_content += """
            </ul>
        </div>

        <div class="section">
            <h2>Visualiza√ß√µes</h2>
            <p>Confira os gr√°ficos gerados para uma an√°lise mais profunda:</p>
            <p>
                <img src="metrics_overview.png" alt="Vis√£o Geral das M√©tricas" style="width: 100%; max-width: 800px; height: auto; margin-bottom: 20px;">
            </p>
            <p>
                <img src="confusion_matrix.png" alt="Matriz de Confus√£o" style="width: 100%; max-width: 600px; height: auto;">
            </p>
        </div>
    </div>
</body>
</html>
"""


        # Salvar relat√≥rio
        report_path = self.results_dir / 'training_evaluation_report.html'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"üìÑ Relat√≥rio HTML salvo em: {report_path}")
        return str(report_path)

    def save_metrics_json(self, metrics: EvaluationMetrics, training_time: float = 0) -> str:
        """Salva m√©tricas em formato JSON."""

        metrics_data = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'training_config': {
                'model': self.config.base_model,
                'epochs': self.config.epochs,
                'batch_size': self.config.batch_size,
                'img_size': self.config.img_size,
                'lr0': self.config.lr0,
                'device': self.config.device,
                'training_time_seconds': training_time
            },
            'evaluation_metrics': {
                'map50': float(metrics.map50),
                'map50_95': float(metrics.map50_95),
                'precision': float(metrics.precision),
                'recall': float(metrics.recall),
                'f1_score': float(metrics.f1_score),
                'inference_time': float(metrics.inference_time),
                'fps': float(metrics.fps)
            },
            'class_metrics': metrics.class_metrics,
            'model_paths': {
                'best_weights': str(Path(self.config.weights_path) / 'visdrone_best.pt'),
                'last_weights': str(Path(self.config.weights_path) / 'visdrone_last.pt')
            }
        }

        json_path = self.results_dir / 'training_metrics.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(metrics_data, f, indent=2, ensure_ascii=False)

        print(f"üìä M√©tricas JSON salvas em: {json_path}")
        return str(json_path)


# ======================================================================================
# --- PIPELINE DE TREINAMENTO ---
# ======================================================================================

class YOLOTrainer:
    """Pipeline de treinamento YOLO."""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.model = None
        self.training_results = None

    def setup_model(self):
        """Configura o modelo YOLO."""
        print(f"ü§ñ Configurando modelo {self.config.base_model}...")

        # Carregar modelo pr√©-treinado
        self.model = YOLO(self.config.base_model)

        print(f"‚úÖ Modelo carregado! Device: {self.config.device}")
        print(f"üìè Par√¢metros: {sum(p.numel() for p in self.model.model.parameters()):,}")

    def train(self):
        """Executa o treinamento."""
        if self.model is None:
            self.setup_model()

        print("üöÄ Iniciando treinamento...")
        print(f"üìä Configura√ß√£o:")
        print(f"   - √âpocas: {self.config.epochs}")
        print(f"   - Batch size: {self.config.batch_size}")
        print(f"   - Tamanho da imagem: {self.config.img_size}")
        print(f"   - Device: {self.config.device}")

        # Configurar argumentos de treinamento
        train_args = {
            'data': str(Path(self.config.dataset_path) / 'dataset.yaml'),
            'epochs': self.config.epochs,
            'batch': self.config.batch_size,
            'imgsz': self.config.img_size,
            'patience': self.config.patience,
            'save': True,
            'device': self.config.device,
            'workers': 4,
            'project': 'runs/detect',
            'name': f'visdrone_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            'exist_ok': True,
            'pretrained': True,
            'optimizer': 'AdamW',
            'lr0': self.config.lr0,
            'momentum': self.config.momentum,
            'weight_decay': self.config.weight_decay,
            'warmup_epochs': self.config.warmup_epochs,
            'box': 7.5,
            'cls': 0.5,
            'dfl': 1.5,
            'plots': True,
            'save_period': 10,  # Salvar checkpoint a cada 10 √©pocas
        }

        try:
            # Executar treinamento
            self.training_results = self.model.train(**train_args)
            print("‚úÖ Treinamento conclu√≠do!")
            return True

        except Exception as e:
            print(f"‚ùå Erro durante o treinamento: {e}")
            return False

    def save_weights(self):
        """Salva os pesos treinados."""
        if self.training_results is None:
            print("‚ùå Nenhum resultado de treinamento encontrado!")
            return False

        try:
            # Copiar pesos para Google Drive
            source_weights = Path(self.training_results.save_dir) / 'weights' / 'best.pt'
            dest_weights = Path(self.config.weights_path) / 'visdrone_best.pt'

            if source_weights.exists():
                shutil.copy2(source_weights, dest_weights)
                print(f"‚úÖ Melhores pesos salvos em: {dest_weights}")

            # Tamb√©m salvar o √∫ltimo
            source_last = Path(self.training_results.save_dir) / 'weights' / 'last.pt'
            dest_last = Path(self.config.weights_path) / 'visdrone_last.pt'

            if source_last.exists():
                shutil.copy2(source_last, dest_last)
                print(f"‚úÖ √öltimos pesos salvos em: {dest_last}")

            return True

        except Exception as e:
            print(f"‚ùå Erro ao salvar pesos: {e}")
            return False


# ======================================================================================
# --- PIPELINE PRINCIPAL ---
# ======================================================================================

def run_complete_training_pipeline():
    """Executa o pipeline completo de treinamento."""
    print("üöÄ INICIANDO PIPELINE DE TREINAMENTO YOLO - VISDRONE")
    print("=" * 60)

    # 1. Configura√ß√£o
    print("\nüìã 1. CONFIGURA√á√ÉO")
    config = TrainingConfig()
    config.create_directories()

    # 2. Valida√ß√£o do dataset
    print("\nüîç 2. VALIDA√á√ÉO DO DATASET")
    validator = DatasetValidator(config)

    if not validator.validate_dataset():
        print("‚ùå Dataset inv√°lido! Execute primeiro o conversor VisDrone.")
        return False

    validator.fix_yaml_paths()
    stats = validator.analyze_dataset()

    # 3. Treinamento
    print("\nü§ñ 3. TREINAMENTO")
    trainer = YOLOTrainer(config)

    if not trainer.train():
        print("‚ùå Treinamento falhou!")
        return False

    # 4. Salvar pesos
    print("\nüíæ 4. SALVANDO PESOS")
    trainer.save_weights()

    print("\nüéâ PIPELINE DE TREINAMENTO CONCLU√çDO COM SUCESSO!")
    print(f"üíæ Pesos salvos em: {config.weights_path}")
    print(f"üìä Logs de treinamento em: {config.results_path}")

    return True


# ======================================================================================
# --- EXECU√á√ÉO ---
# ======================================================================================

if __name__ == "__main__":
    # Executar pipeline completo
    success = run_complete_training_pipeline()

    if success:
        print("\n‚úÖ Tudo pronto! Seu modelo YOLO foi treinado com sucesso!")
        print("üîß Para usar o modelo:")
        print("   from ultralytics import YOLO")
        print("   model = YOLO('/content/drive/MyDrive/visdrone_weights/visdrone_best.pt')")
        print("   results = model('sua_imagem.jpg')")
    else:
        print("\n‚ùå Algo deu errado. Verifique os logs acima.")